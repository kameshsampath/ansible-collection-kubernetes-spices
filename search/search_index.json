{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A Ansible collection to install various components on to Kubernetes clusters. Currently the following components can be installed, Argocd Gitea Knative Tektoncd","title":"Overview"},{"location":"role_argocd/","text":"This role helps in installing and configuring Argocd the Kubernetes cluster. Requirements \u00b6 Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\" Variables \u00b6 Name Description Default kubernetes_spices_argocd_k8s_context The Kubernetes context where Argcod will be installed. The playbook will fail if this is not set. kubernetes_spices_argocd_namespace The namespace to install Argocd argocd kubernetes_spices_argocd_version The argocd version to be used 2.1.6 kubernetes_spices_argocd_helm_secerts_plugin Use helm secrets plugin with argocd applications false Example Playbook \u00b6 - name : \"Setup Argocd\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.argocd } Important Based on the above example the kubernetes_spices_argocd_k8s_context should be set to mgmt , the context which is created by minikube The default credentials to access argocd will be admin/password Using helm secrets plugin \u00b6 To use helm secrets plugin with Argocd applications, enable the plugin configuration by adding enable the flag kubernetes_spices_argocd_helm_secerts_plugin to true . Lets take an example of sops and age , Create age key \u00b6 age-keygen -o key.txt Move the key.txt to secure place, preferably $HOME/.ssh . Assuming you moved it to $HOME/.ssh , lets set that as local environment variables for convinience: export SOPS_AGE_KEY_FILE = \" $HOME /.ssh/key.txt\" Also note and export the publickey in the $SOPS_AGE_KEY_FILE as $SOPS_AGE_RECIPIENTS export SOPS_AGE_RECIPIENTS = $( cat $SOPS_AGE_KEY_FILE | awk 'NR==2{ print $4}' ) Ensure the sops configration .sops.yml is updated with your age publickey, yq eval '.creation_rules[0].age |= strenv(SOPS_AGE_RECIPIENTS)' .sops.yml We need to make the age key to be available to the Argocd repo server so that it can decrypt the secrets, kubectl create ns argocd kubectl create secret generic helm-secrets-private-keys \\ --namespace = argocd \\ --from-file = key.txt = \" $SOPS_AGE_KEY_FILE \" Now you an use the same play to deploy Argocd with helm secrets enabled, - name : \"Setup Argocd\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.argocd } You can check the example project to deploy Keycloak using helm secrets plugin enabled with Argocd.","title":"Argocd"},{"location":"role_argocd/#requirements","text":"Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\"","title":"Requirements"},{"location":"role_argocd/#variables","text":"Name Description Default kubernetes_spices_argocd_k8s_context The Kubernetes context where Argcod will be installed. The playbook will fail if this is not set. kubernetes_spices_argocd_namespace The namespace to install Argocd argocd kubernetes_spices_argocd_version The argocd version to be used 2.1.6 kubernetes_spices_argocd_helm_secerts_plugin Use helm secrets plugin with argocd applications false","title":"Variables"},{"location":"role_argocd/#example-playbook","text":"- name : \"Setup Argocd\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.argocd } Important Based on the above example the kubernetes_spices_argocd_k8s_context should be set to mgmt , the context which is created by minikube The default credentials to access argocd will be admin/password","title":"Example Playbook"},{"location":"role_argocd/#using-helm-secrets-plugin","text":"To use helm secrets plugin with Argocd applications, enable the plugin configuration by adding enable the flag kubernetes_spices_argocd_helm_secerts_plugin to true . Lets take an example of sops and age ,","title":"Using helm secrets plugin"},{"location":"role_argocd/#create-age-key","text":"age-keygen -o key.txt Move the key.txt to secure place, preferably $HOME/.ssh . Assuming you moved it to $HOME/.ssh , lets set that as local environment variables for convinience: export SOPS_AGE_KEY_FILE = \" $HOME /.ssh/key.txt\" Also note and export the publickey in the $SOPS_AGE_KEY_FILE as $SOPS_AGE_RECIPIENTS export SOPS_AGE_RECIPIENTS = $( cat $SOPS_AGE_KEY_FILE | awk 'NR==2{ print $4}' ) Ensure the sops configration .sops.yml is updated with your age publickey, yq eval '.creation_rules[0].age |= strenv(SOPS_AGE_RECIPIENTS)' .sops.yml We need to make the age key to be available to the Argocd repo server so that it can decrypt the secrets, kubectl create ns argocd kubectl create secret generic helm-secrets-private-keys \\ --namespace = argocd \\ --from-file = key.txt = \" $SOPS_AGE_KEY_FILE \" Now you an use the same play to deploy Argocd with helm secrets enabled, - name : \"Setup Argocd\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.argocd } You can check the example project to deploy Keycloak using helm secrets plugin enabled with Argocd.","title":"Create age key"},{"location":"role_gitea/","text":"This role helps in installing and configuring Gitea the Kubernetes cluster. Requirements \u00b6 Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\" Variables \u00b6 Name Description Default kubernetes_spices_gitea_k8s_context The Kubernetes context where Gitea will be installed. The playbook will fail if this is not set. kubernetes_spices_gitea_namespace The namespace to install Gitea gitea kubernetes_spices_gitea_cli_version The gitea cli version 1.15.6 Example Playbook \u00b6 - name : \"Setup Gitea\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.gitea } Important Based on the above example the kubernetes_spices_gitea_k8s_context should be set to mgmt , the context which is created by minikube The gitea password will be generated and stored in the {{ work_dir }}/gitea.password file. The default admin username is gitea The playbook installs a proxy in the namespace where Gitea is installed to allow the service to be accessed from the host machine. To get your gitea url run, GITEA_URL = gitea- $( kubectl -n gitea gateway-proxy -ojsonpath = '{.status.loadBalancer.ingress[*].ip}' ) .nip.io \"","title":"Gitea"},{"location":"role_gitea/#requirements","text":"Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\"","title":"Requirements"},{"location":"role_gitea/#variables","text":"Name Description Default kubernetes_spices_gitea_k8s_context The Kubernetes context where Gitea will be installed. The playbook will fail if this is not set. kubernetes_spices_gitea_namespace The namespace to install Gitea gitea kubernetes_spices_gitea_cli_version The gitea cli version 1.15.6","title":"Variables"},{"location":"role_gitea/#example-playbook","text":"- name : \"Setup Gitea\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.gitea } Important Based on the above example the kubernetes_spices_gitea_k8s_context should be set to mgmt , the context which is created by minikube The gitea password will be generated and stored in the {{ work_dir }}/gitea.password file. The default admin username is gitea The playbook installs a proxy in the namespace where Gitea is installed to allow the service to be accessed from the host machine. To get your gitea url run, GITEA_URL = gitea- $( kubectl -n gitea gateway-proxy -ojsonpath = '{.status.loadBalancer.ingress[*].ip}' ) .nip.io \"","title":"Example Playbook"},{"location":"role_knative/","text":"This role helps in installing and configuring Knative Serving and Eventing on to the Kubernetes cluster. Requirements \u00b6 Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\" Variables \u00b6 Name Description Default kubernetes_spices_gitea_k8s_context The Kubernetes context where Knative will be installed. The playbook will fail if this is not set. kubernetes_spices_knative_serving_version The Knative Serving version to use v1.0.0 kubernetes_spices_knative_eventing_version The Knative Eventing version to use v1.0.0 kubernetes_spices_registries_skip_tag_resolving The list of registry urls which need to be ignored for tag resolving example.com,example.org,test.com,test.org,ko.local,dev.local,localhost:5000,kind-registry.local:5000 Example Playbook \u00b6 - name : \"Setup Knative\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.knative } Important Based on the above example the kubernetes_spices_knative_k8s_context should be set to mgmt , the context which is created by minikube.","title":"Knative"},{"location":"role_knative/#requirements","text":"Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\"","title":"Requirements"},{"location":"role_knative/#variables","text":"Name Description Default kubernetes_spices_gitea_k8s_context The Kubernetes context where Knative will be installed. The playbook will fail if this is not set. kubernetes_spices_knative_serving_version The Knative Serving version to use v1.0.0 kubernetes_spices_knative_eventing_version The Knative Eventing version to use v1.0.0 kubernetes_spices_registries_skip_tag_resolving The list of registry urls which need to be ignored for tag resolving example.com,example.org,test.com,test.org,ko.local,dev.local,localhost:5000,kind-registry.local:5000","title":"Variables"},{"location":"role_knative/#example-playbook","text":"- name : \"Setup Knative\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.knative } Important Based on the above example the kubernetes_spices_knative_k8s_context should be set to mgmt , the context which is created by minikube.","title":"Example Playbook"},{"location":"role_tektoncd/","text":"This role helps in installing and configuring Tektoncd on to the Kubernetes cluster. Requirements \u00b6 Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\" Variables \u00b6 Name Description Default kubernetes_spices_tektoncd_k8s_context The Kubernetes context where Tektoncd will be installed. The playbook will fail if this is not set. kubernetes_spices_tektoncd_pipelines_version The Tekton pipelines version to use v0.29.0 kubernetes_spices_tektoncd_triggers_version The Tekton triggers version to use v0.16.0 kubernetes_spices_tkn_cli_version The tkn cli version v0.21.0 Example Playbook \u00b6 - name : \"Setup Knative\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.knative } Important Based on the above example the kubernetes_spices_tektoncd_k8s_context should be set to mgmt , the context which is created by minikube.","title":"Tektoncd"},{"location":"role_tektoncd/#requirements","text":"Access to Kubernetes cluster, For demo purpose you can have minikube cluster created locally as shown in the following example playbook, e.g. - name : \"Create minikube Clusters\" hosts : all vars : # the demo work directory work_dir : \"{{ playbook_dir }}/work\" # the kubeconfig directory kubeconfig_dir : \"{{ work_dir }}/.kube\" # the kubernetes version to use with minikube minikube_kubernetes_version : v1.21.6 # the minikube home directory minikube_home_dir : \"{{ work_dir }}/.minikube\" # minikube profiles minikube_profiles : mgmt : # profile name and Kubernetes context name create : yes destroy : no addons : - metallb lbStartIP : 192.168.64.80 lbEndIP : 192.168.64.90 roles : - role : kameshsampath.minikube # Some extra configurations tasks : - name : \"Configure metallb\" ansible.builtin.expect : command : \"{{ minikube_binary }} -p {{ item.key }} addons configure metallb\" responses : \"-- Enter Load Balancer Start IP:\" : \"{{ item.value.lbStartIP}}\" \"-- Enter Load Balancer End IP:\" : \"{{ item.value.lbEndIP}}\" loop : \"{{ minikube_profiles | dict2items }}\" loop_control : label : \"{{ item.key }}\" register : lb_setup_result when : item.value.create and not item.value.destroy - name : \"Metallb result\" debug : var : lb_setup_result - name : \"Ensure we are in mgmt context\" ansible.builtin.command : argv : - kubectl - config - use-context - \"mgmt\" environment : KUBECONFIG : \"{{ work_dir }}/.kube/config\" - name : \"Ensure right permissions to kubeconfig directory\" ansible.builtin.file : state : directory recurse : yes path : \"{{ work_dir }}/.kube\" mode : \"0700\"","title":"Requirements"},{"location":"role_tektoncd/#variables","text":"Name Description Default kubernetes_spices_tektoncd_k8s_context The Kubernetes context where Tektoncd will be installed. The playbook will fail if this is not set. kubernetes_spices_tektoncd_pipelines_version The Tekton pipelines version to use v0.29.0 kubernetes_spices_tektoncd_triggers_version The Tekton triggers version to use v0.16.0 kubernetes_spices_tkn_cli_version The tkn cli version v0.21.0","title":"Variables"},{"location":"role_tektoncd/#example-playbook","text":"- name : \"Setup Knative\" hosts : localhost vars : kubernetes_spices_argocd_k8s_context : 'mgmt' roles : - { role : kameshsampath.kubernetes_spices.knative } Important Based on the above example the kubernetes_spices_tektoncd_k8s_context should be set to mgmt , the context which is created by minikube.","title":"Example Playbook"}]}